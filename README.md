# Credit Risk Analysis
Evaluating models for loan predication risk analysis 
------

# Overview 
This evaluation demonstrates the value of various computational models when a multitude of factors affect one desicion. Imagine there are 85 factors to weigh - it is difficult to demonstrate on a bar chart or an algebraic equation, so we compute these factors. However, computations are run with the bias of the designer in mind, and may not be the most accurate lens to view the data.

Here, we look at credit risk data, provided [here](https://github.com/emilymcdaniel/Credit_Risk_Analysis/blob/main/LoanStats_2019Q1.zip) to determine the impact on whether an individual is deemed "high risk" or "low risk".

-----

# Results: 
Each decision model weighs data differently. Let's look at the balanced accuracy scores, precision, and recall differences within each model:

## Model 1: RandomOverSampler 
- Balanced accuracy score:
- Precision:
- Recall:
## Model 2: SMOTE (oversampling)
- Balanced accuracy score:
- Precision:
- Recall:
## Model 3: ClusterCentroids (undersampling)
- Balanced accuracy score:
- Precision:
- Recall:
## Model 4: SMOTEENN (a combinatorial approach of over- and undersampling)
- Balanced accuracy score:
- Precision:
- Recall:
## Model 5: BalancedRandomForestClassifier 
- Balanced accuracy score:
- Precision:
- Recall:
## Model 6: EasyEnsembleClassifier 
- Balanced accuracy score:
- Precision:
- Recall:
Using bulleted lists, describe the balanced accuracy scores and the precision and recall scores of all six machine learning models. Use screenshots of your outputs to support your results.

-----

# Summary: 
Summarize the results of the machine learning models, and include a recommendation on the model to use, if any. 

## Model Recommendation
If you do not recommend any of the models, justify your reasoning.



Links to images are working, and code is formatted and displayed correctly (2 pt).
